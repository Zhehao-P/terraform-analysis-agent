# The transport for the MCP server - either 'sse' or 'stdio' (defaults to SSE if left empty)
TRANSPORT=

# Host to bind to if using sse as the transport (leave empty if using stdio)
HOST=

# Port to listen on if using sse as the transport (leave empty if using stdio)
PORT=

#######################
# API CONFIGURATION
#######################
# ALL FIELDS BELOW ARE REQUIRED

# 1. API Key (REQUIRED)
# Your API key for accessing embedding services
LLM_API_KEY=your_api_key_here

# 2. API Base URL (REQUIRED)
# The base URL for the OpenAI-compatible API
# Example: https://api.openai.com/v1
LLM_BASE_URL=https://api.openai.com/v1

# 3. Embedding Model (REQUIRED)
# The model to use for creating embeddings
# Examples:
# - text-embedding-3-small
# - text-embedding-3-large
# - Any other model compatible with your API
EMBEDDING_MODEL_CHOICE=text-embedding-3-small

# 4. Embedding Dimensions (OPTIONAL)
# The number of dimensions for the embedding vectors
# Default: 1024
EMBEDDING_DIMENSIONS=

# 5. Debug Mode (OPTIONAL)
# Set to any value to enable DEBUG level logging
# If not set or left empty, logging will be at INFO level
DEBUG=

#######################
# DATA CONFIGURATION
#######################

# Subdirectories for different types of data
GITHUB_DIR=data/github

# Qdrant configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=knowledge_db
